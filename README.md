# ğŸ“§ Classificador Inteligente de E-mails

Projeto de IA que classifica e responde e-mails automaticamente:

- **Produtivo** â†’ requer aÃ§Ã£o/resposta (ex: dÃºvidas, suporte, problemas).  
- **Improdutivo** â†’ nÃ£o requer aÃ§Ã£o (ex: agradecimentos, parabÃ©ns, comunicaÃ§Ãµes genÃ©ricas).  

O sistema utiliza **FastAPI (backend)** + **Next.js (frontend)** com suporte a **modelos OpenAI** e **Hugging Face**.

---

## ğŸš€ Tecnologias
- **Backend**: Python 3.10+, FastAPI, Transformers, OpenAI SDK  
- **Frontend**: Next.js 14, TypeScript, TailwindCSS  
- **IA**:
  - ClassificaÃ§Ã£o â†’ `MoritzLaurer/mDeBERTa-v3-base-mnli-xnli` (HF) ou GPT  
  - GeraÃ§Ã£o de resposta â†’ `unicamp-dl/ptt5-base-portuguese-vocab`, `flan-t5` ou GPT  

---

## ğŸ“‚ Estrutura do Projeto

```
Pratico-AutoU/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app.py              # Endpoints FastAPI
â”‚       â”œâ”€â”€ services/           # ServiÃ§os de NLP e classificaÃ§Ã£o
â”‚       â”œâ”€â”€ preprocessingService.py
â”‚       â””â”€â”€ replyService.py
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â”œâ”€â”€ app/                # App Router (Next.js 14)
        â””â”€â”€ components/         # UploadForm
```

---

## âš™ï¸ ConfiguraÃ§Ã£o Local

### 1. Clone o projeto
```bash
git clone https://github.com/guissx/Pratico-AutoU.git
cd Pratico-AutoU
```

### 2. Backend (FastAPI)

#### Criar venv e instalar dependÃªncias

```bash
cd backend
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
```

#### Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` dentro de `backend/`:

```
OPENAI_API_KEY=sk-xxxx
HF_MODEL=MoritzLaurer/mDeBERTa-v3-base-mnli-xnli
HF_GENERATOR=unicamp-dl/ptt5-base-portuguese-vocab
```

#### Rodar servidor

```bash
uvicorn src.app:app --reload --port 8000
```

Servidor local â†’ [http://localhost:8000/docs](http://localhost:8000/docs)

---

### 3. Frontend (Next.js)

#### Instalar dependÃªncias

```bash
cd ../frontend
npm install
```

#### Rodar servidor de dev

```bash
npm run dev
```

Frontend local â†’ [http://localhost:3000](http://localhost:3000)

---

## ğŸŒ Deploy em ProduÃ§Ã£o

* **Frontend**: [Vercel](https://pr-tico-auto-u-front-h66duebh8-guissxs-projects.vercel.app/) â†’ conectar repositÃ³rio `frontend/`
* **Backend**:
  * [Render](https://render.com/), [Railway](https://railway.app/) ou AWS EC2
  * Configure variÃ¡veis de ambiente no painel de deploy
  * Exponha a API (ex: `https://seu-backend.com/classify`)

âš ï¸ Importante: no `frontend/src/components/UploadForm.tsx`, ajuste a constante `apiBase` para a URL do backend em produÃ§Ã£o.

```ts
const apiBase = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8000";
```

No `.env.local` do frontend:

```
NEXT_PUBLIC_API_URL=https://seu-backend.com
```

---

## ğŸ§ª Testes RÃ¡pidos

### Endpoint de SaÃºde

```bash
curl http://localhost:8000/health
```

### Upload via cURL

```bash
curl -X POST "http://localhost:8000/classify?provider=openai" \
  -F "file=@exemplo_email.txt"
```

---

## âœ… Checklist

* [x] Upload de PDF/TXT
* [x] PrÃ©-processamento (limpeza, normalizaÃ§Ã£o, stemming opcional)
* [x] ClassificaÃ§Ã£o com OpenAI ou Hugging Face
* [x] GeraÃ§Ã£o de resposta automÃ¡tica
* [x] Interface web com upload e exibiÃ§Ã£o dos resultados

---

ğŸ‘¨â€ğŸ’» **Autor**: Gustavo Ferreira Cabral
ğŸ“Œ Projeto para estudo de **IA Generativa + NLP + Web Fullstack**

---

